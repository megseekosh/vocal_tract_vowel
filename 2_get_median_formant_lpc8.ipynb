{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from espspy.readers import EspsFormantReader\n",
    "import os, sys, fnmatch\n",
    "from audiolabel import read_label\n",
    "import re\n",
    "import pandas as pd\n",
    "from sys import argv\n",
    "from phonlab.utils import dir2df\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get textgrid information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgdir = ('/home/ubuntu/Desktop/Shared/sf_Box_Sync/Diss_data/Fall_2019_LRAP/Word_lists/2018_vowels/2018_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnpat = '^(?P<spkr>[^_]+)_(?P<age_yrs>\\d+|adult)_(?P<task>.+)\\.TextGrid$' # filenames\n",
    "\n",
    "tgdf = dir2df(\n",
    "    tgdir,\n",
    "    fnpat=fnpat,\n",
    "    addcols=['dirname', 'barename', 'ext']   # addcols spits out relevant file names\n",
    ")\n",
    "tgdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only get children aged 4-6\n",
    "tgdf = tgdf[\n",
    "    tgdf.age_yrs.isin(['4', '5', '6']) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = []\n",
    "for row in tgdf.itertuples():\n",
    "    print(row.dirname+row.fname)\n",
    "    [phdf, wddf] = read_label(\n",
    "        os.path.join(row.dirname,row.fname), \n",
    "        'praat', tiers = ['Phone','Word'], \n",
    "        addcols=['dirname', 'barename', 'ext']\n",
    "    )   \n",
    "                             \n",
    "    dflist.append(pd.merge_asof(phdf, wddf, on='t1', suffixes=['_ph', '_wd']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phwddf = pd.concat(dflist) # one df for all kids with words and phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffinal = phwddf.merge(\n",
    "    tgdf,\n",
    "    left_on=['barename_ph'], \n",
    "    right_on=['barename'],\n",
    "    how='outer'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to create df with just relevant vowels\n",
    "voweldf = dffinal[\n",
    "    dffinal.Phone.isin(['a', 'e', 'i', 'o', 'u']) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove tokens under 50ms\n",
    "voweldf2 = voweldf[voweldf.t2_ph - voweldf.t1 >= .05] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset only the relevant children (aged 4-6)\n",
    "subchild = voweldf2[voweldf2.age_yrs.isin(['4', '5', '6'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function matches tg rows with nearest timestamp in covrdrdf, acdf, or ifcdf,  \n",
    "# and is required for the following functions\n",
    "# current version only tracks F1 and F2 as these are the only formants\n",
    "# tracked when lpc order=8\n",
    "\n",
    "def get_row_nearest_time(df, t, timecol): # timecol = timestamp col in df\n",
    "    '''Get the row nearest in time to specified value.\n",
    "    In case of tie, first row is returned.\n",
    "    ***NOTE***\n",
    "    df[timecol] must be sorted!!!\n",
    "    '''\n",
    "    return pd.DataFrame.from_records([df.loc[(df[timecol] - t).abs().idxmin()]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process \"formant\" .cov results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to match .cov meas and tg info\n",
    "\n",
    "def formant_cov_summary(row):\n",
    "    phone_dur = row.t2_ph - row.t1\n",
    "    midpt = (phone_dur*.5)+row.t1 \n",
    "    qrtr = (phone_dur*.25)+row.t1 \n",
    "    thrqrtr = (phone_dur*.75)+row.t1 \n",
    "\n",
    "    covdir = ('/home/ubuntu/Desktop/Shared/sf_Box_Sync/Diss_data/Fall_2019_LRAP/Word_lists/2018_vowels/2018_data/formants_cov_lpcorder_8')\n",
    "\n",
    "    covdr = EspsFormantReader(os.path.join(covdir, row.barename + '.fb')) # make an ESPS object of the associated .fb file\n",
    "    covdrdf = covdr.get_df(t1=row.t1, t2=row.t2_ph) # \n",
    "\n",
    "    midptrow = get_row_nearest_time(covdrdf, midpt, 'times')\n",
    "    midptdf = midptrow.rename(columns={\"times\": \"midpt_sec\", \"fm1\": \"midpt_f1\", \"fm2\": \"midpt_f2\"})\n",
    "    qrtrrow = get_row_nearest_time(covdrdf, qrtr, 'times')\n",
    "    qrtrdf = qrtrrow.rename(columns={\"times\": \"qrtr_sec\", \"fm1\": \"qrtr_f1\", \"fm2\": \"qrtr_f2\"})\n",
    "    thrqrtrrow = get_row_nearest_time(covdrdf, thrqrtr, 'times')\n",
    "    thrqrtrdf = thrqrtrrow.rename(columns={\"times\": \"thrqrtr_sec\", \"fm1\": \"thrqrtr_f1\", \"fm2\": \"thrqrtr_f2\"})\n",
    "\n",
    "    rowdf = pd.DataFrame([row])\n",
    "\n",
    "    rowdffinal = rowdf.reindex(columns=['t1', 't2_ph', 'Phone', 'barename', 'Word', 'spkr', 'age_yrs', 'task']) # :=all rows, and these columns\n",
    "\n",
    "    return pd.concat(\n",
    "        [\n",
    "            midptdf.reindex(columns=['midpt_sec', 'midpt_f1', 'midpt_f2']), # subset relevant cols\n",
    "            qrtrdf.reindex(columns=['qrtr_sec', 'qrtr_f1', 'qrtr_f2']),\n",
    "            thrqrtrdf.reindex(columns=['thrqrtr_sec', 'thrqrtr_f1', 'thrqrtr_f2']),\n",
    "            rowdffinal # plus cols w/ metadata\n",
    "        ], \n",
    "        axis='columns' # add cols, not rows\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run the function to match formant meas and tg info\n",
    "\n",
    "covdflist = []\n",
    "\n",
    "for row in subchild.itertuples(): \n",
    "    covdflist.append(formant_cov_summary(row)) \n",
    "\n",
    "cov_final = pd.concat(covdflist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process \"formant\" .ac results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to match .ac meas and tg info\n",
    "\n",
    "def formant_ac_summary(row):\n",
    "    phone_dur = row.t2_ph - row.t1\n",
    "    midpt = (phone_dur*.5)+row.t1 \n",
    "    qrtr = (phone_dur*.25)+row.t1 \n",
    "    thrqrtr = (phone_dur*.75)+row.t1 \n",
    "\n",
    "    acdir = ('/home/ubuntu/Desktop/Shared/sf_Box_Sync/Diss_data/Fall_2019_LRAP/Word_lists/2018_vowels/2018_data/formants_ac_lpcorder_8')\n",
    "\n",
    "    acrdr = EspsFormantReader(os.path.join(acdir, row.barename + '.fb')) # make an ESPS object of the associated .fb file\n",
    "    acrdrdf = acrdr.get_df(t1=row.t1, t2=row.t2_ph) # \n",
    "\n",
    "    midptrow = get_row_nearest_time(acrdrdf, midpt, 'times')\n",
    "    midptdf = midptrow.rename(columns={\"times\": \"midpt_sec\", \"fm1\": \"midpt_f1\", \"fm2\": \"midpt_f2\"})\n",
    "    qrtrrow = get_row_nearest_time(acrdrdf, qrtr, 'times')\n",
    "    qrtrdf = qrtrrow.rename(columns={\"times\": \"qrtr_sec\", \"fm1\": \"qrtr_f1\", \"fm2\": \"qrtr_f2\"})\n",
    "    thrqrtrrow = get_row_nearest_time(acrdrdf, thrqrtr, 'times')\n",
    "    thrqrtrdf = thrqrtrrow.rename(columns={\"times\": \"thrqrtr_sec\", \"fm1\": \"thrqrtr_f1\", \"fm2\": \"thrqrtr_f2\"})\n",
    "\n",
    "    rowdf = pd.DataFrame([row])\n",
    "\n",
    "    rowdffinal = rowdf.reindex(columns=['t1', 't2_ph', 'Phone', 'barename', 'Word', 'spkr', 'age_yrs', 'task']) # :=all rows, and these columns\n",
    "\n",
    "    return pd.concat(\n",
    "        [\n",
    "            midptdf.reindex(columns=['midpt_sec', 'midpt_f1', 'midpt_f2']), # subset relevant cols\n",
    "            qrtrdf.reindex(columns=['qrtr_sec', 'qrtr_f1', 'qrtr_f2']),\n",
    "            thrqrtrdf.reindex(columns=['thrqrtr_sec', 'thrqrtr_f1', 'thrqrtr_f2']),\n",
    "            rowdffinal # plus cols w/ metadata\n",
    "        ], \n",
    "        axis='columns' # add cols, not rows\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run the function to match formant meas and tg info\n",
    "\n",
    "acdflist = []\n",
    "\n",
    "for row in voweldf2.itertuples(): \n",
    "    acdflist.append(formant_ac_summary(row)) \n",
    "\n",
    "ac_final = pd.concat(acdflist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process ifc_formant results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to match meas and tg info\n",
    "\n",
    "def ifc_summary(row):\n",
    "    \n",
    "    phone_dur = row.t2_ph - row.t1\n",
    "    midpt = (phone_dur*.5)+row.t1 \n",
    "    qrtr = (phone_dur*.25)+row.t1 \n",
    "    thrqrtr = (phone_dur*.75)+row.t1 \n",
    "    \n",
    "    ifcdir = ('/home/ubuntu/Desktop/Shared/sf_Box_Sync/Diss_data/Fall_2019_LRAP/Word_lists/2018_vowels/2018_data/formants_ifc')\n",
    "\n",
    "    ifcname = row.barename + '.ifc' # get ifc filename (just a string)\n",
    "    df = pd.read_table(os.path.join(ifcdir, ifcname)) # big df of ifc values\n",
    "\n",
    "    midptrow = get_row_nearest_time(df, midpt, 'sec')\n",
    "    midptdf = midptrow.rename(columns={\"sec\": \"midpt_sec\", \"f1\": \"midpt_f1\", \"f2\": \"midpt_f2\", \"f3\": \"midpt_f3\", \"f4\": \"midpt_f4\"})\n",
    "    qrtrrow = get_row_nearest_time(df, qrtr, 'sec')\n",
    "    qrtrdf = qrtrrow.rename(columns={\"sec\": \"qrtr_sec\", \"f1\": \"qrtr_f1\", \"f2\": \"qrtr_f2\", \"f3\": \"qrtr_f3\", \"f4\": \"qrtr_f4\"})\n",
    "    thrqrtrrow = get_row_nearest_time(df, thrqrtr, 'sec')\n",
    "    thrqrtrdf = thrqrtrrow.rename(columns={\"sec\": \"thrqrtr_sec\", \"f1\": \"thrqrtr_f1\", \"f2\": \"thrqrtr_f2\", \"f3\": \"thrqrtr_f3\", \"f4\": \"thrqrtr_f4\"})\n",
    "\n",
    "    rowdf = pd.DataFrame([row])\n",
    "\n",
    "    rowdffinal = rowdf.reindex(columns=['t1', 't2_ph', 'Phone', 'barename', 'Word', 'spkr', 'age_yrs', 'task']) # :=all rows, and these columns\n",
    "\n",
    "    return pd.concat([midptdf, qrtrdf, thrqrtrdf, rowdffinal], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function to match ifc meas and tg info\n",
    "ifclist = []\n",
    "\n",
    "\n",
    "for row in voweldf2.itertuples(): \n",
    "    ifclist.append(ifc_summary(row))\n",
    "  \n",
    "\n",
    "ifc_final = pd.concat(ifclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifc_final.head() # sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove F3 and F4 from lpc because we don't need it\n",
    "ifc_final = ifc_final.drop(['midpt_f3', 'qrtr_f3', 'thrqrtr_f3', 'midpt_f3', 'qrtr_f3', 'thrqrtr_f3', 'midpt_f4', 'qrtr_f4', 'thrqrtr_f4'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge results from three trackers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats = ['Phone', 't2_ph', 'Word', 'spkr', 'age_yrs', 'task']\n",
    "\n",
    "gettwo = pd.merge(    # merge ifc and ac dfs on filename and phone_t1\n",
    "    ifc_final, \n",
    "    ac_final.drop(repeats, axis='columns'),  \n",
    "    on=['barename', 't1'], \n",
    "    how='outer', \n",
    "    suffixes=['_ifc', '_ac']\n",
    ") \n",
    "\n",
    "allthree = pd.merge(    # merge ifc, ac, and cov dfs on filename and phone_t1\n",
    "    gettwo, \n",
    "    cov_final.drop(repeats, axis='columns'),  \n",
    "    on=['barename', 't1'], \n",
    "    how='outer'\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check - if every key had a match, should report FALSE\n",
    "np.any(allthree.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate median formant meas for each point in vowel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median(row):\n",
    "    \n",
    "    # first clean up metadata\n",
    "    tokeep = ['spkr', 'age_yrs', 'Phone', 'Word', 'barename', 'task', 't1', 't2_ph',\n",
    "             'qrtr_sec', 'midpt_sec', 'thrqrtr_sec', 'qrtr_sec_ifc', 'midpt_sec_ifc', 'thrqrtr_sec_ifc',\n",
    "             'qrtr_sec_ac', 'midpt_sec_ac', 'thrqrtr_sec_ac']\n",
    "    \n",
    "    \n",
    "    rowdf = pd.DataFrame([row]).rei[:, tokeep]\n",
    "    \n",
    "    \n",
    "    # now calculate median formant across trackers and formants\n",
    "    f1_qrtr = pd.DataFrame([\n",
    "        np.median(\n",
    "            np.array(\n",
    "                [row.qrtr_f1_ifc, row.qrtr_f1, row.qrtr_f1_ac]))], columns=['f1_qrtr_med'])\n",
    "    f1_midpt = pd.DataFrame([\n",
    "        np.median(\n",
    "            np.array(\n",
    "                [row.midpt_f1_ifc, row.midpt_f1, row.midpt_f1_ac]))], columns=['f1_midpt_med'])\n",
    "    f1_thrqrtr = pd.DataFrame([\n",
    "        np.median(\n",
    "            np.array(\n",
    "                [row.thrqrtr_f1_ifc, row.thrqrtr_f1, row.thrqrtr_f1_ac]))], columns=['f1_thrqrtr_med'])\n",
    "    \n",
    "    f2_qrtr = pd.DataFrame([\n",
    "        np.median(\n",
    "            np.array(\n",
    "                [row.qrtr_f2_ifc, row.qrtr_f2, row.qrtr_f2_ac]))], columns=['f2_qrtr_med'])\n",
    "    f2_midpt = pd.DataFrame([\n",
    "        np.median(\n",
    "            np.array(\n",
    "                [row.midpt_f2_ifc, row.midpt_f2, row.midpt_f2_ac]))], columns=['f2_midpt_med'])\n",
    "    f2_thrqrtr = pd.DataFrame(\n",
    "        [np.median(\n",
    "            np.array(\n",
    "                [row.thrqrtr_f2_ifc, row.thrqrtr_f2, row.thrqrtr_f2_ac]))], columns=['f2_thrqrtr_med'])\n",
    "\n",
    "    return pd.concat([f1_qrtr,  f1_midpt, f1_thrqrtr,\n",
    "                          f2_qrtr, f2_midpt, f2_thrqrtr,\n",
    "                          rowdf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now calculate median meas for each formant at 25, 50, and 75% of each vowel\n",
    "\n",
    "medlist = []\n",
    "\n",
    "for row in allthree.itertuples(): # loop through all rows in the df with ifc, cov, and ac measurements\n",
    "    get_median(row)\n",
    "    medlist.append(get_median(row))\n",
    "  \n",
    "\n",
    "medfinal = pd.concat(medlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medfinal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data\n",
    "medfinal.to_csv('med_formants_lpcorder_8.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for outliers\n",
    "Plot some histograms to identify outliers on a by-participant and by-age group basis to determine if we should retrack formants with a different LPC order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker = \"AnaValeria\" # specify the child\n",
    "\n",
    "sub_df = medfinal.loc[(medfinal.spkr==speaker)]  # subset speakers and vowels.\n",
    "\n",
    "ax2 = sns.distplot(sub_df[\"f1_qrtr_med\"], hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 3})\n",
    "sns.distplot(sub_df[\"f2_qrtr_med\"], hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 3},ax=ax2)\n",
    "\n",
    "ax2.set(xlabel='Formant frequency (Hz)', ylabel='Probability density')\n",
    "ax2.text(350,0.001,\"F1\")\n",
    "ax2.text(1200,0.0003,\"F2\")\n",
    "ax2.text(3000,0.001,speaker,fontsize=22)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "option to check by age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(medfinal.age_yrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#medfinal.age_yrs = chr(medfinal.age_yrs)\n",
    "for a in medfinal.age_yrs.unique():\n",
    "        \n",
    "    sub_df = medfinal.loc[(medfinal.age_yrs==a)]  # select age group\n",
    "\n",
    "    plt.figure(a) # to separate the plots (remove if want overlaid)\n",
    "    ax2 = sns.distplot(sub_df[\"f1_qrtr_med\"], hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 3})\n",
    "    sns.distplot(sub_df[\"f2_qrtr_med\"], hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 3},ax=ax2)\n",
    "    sns.distplot(sub_df[\"f3_qrtr_med\"], hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 3},ax=ax2)\n",
    "\n",
    "    ax2.set(xlabel='Formant frequency (Hz)', ylabel='Probability density')\n",
    "    ax2.text(350,0.001,\"F1\")\n",
    "    ax2.text(1200,0.0003,\"F2\")\n",
    "    ax2.text(2300,0.0004,\"F3\")\n",
    "    ax2.text(3000,0.001,a,fontsize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate each speaker's vocal tract length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vtl(d):\n",
    "    deltaf = (np.mean(d.f1)/0.5 + np.mean(d.f2)/1.5 + np.mean(d.f3)/2.5 + np.mean(d.f4)/3.5)/4\n",
    "    vtl = 34000/(2*deltaf)\n",
    "\n",
    "    # Here is the Lammert & Nagarayan formula:  229 + 0.03F1 + 0.082*F2/3 + 0.124*F3/5 + 0.354*F4/7\n",
    "    #phi = 229 + 0.030*np.mean(d.f1) + 0.02733*np.mean(d.f2) + 0.0248*np.mean(d.f3) + 0.05057*np.mean(d.f4)\n",
    "    #vtl = 34000/(4*phi)\n",
    "    #deltaf = phi*2\n",
    "    \n",
    "    return deltaf,vtl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "once we have vtl and speaking rate controlled for, what are the remaining differences \n",
    "between adults and kids? these are due to the morphology of the vt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
