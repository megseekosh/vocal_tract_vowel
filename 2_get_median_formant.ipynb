{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate median formant from triple formant tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from espspy.readers import EspsFormantReader\n",
    "import os, sys, fnmatch\n",
    "from audiolabel import read_label\n",
    "import re\n",
    "import pandas as pd\n",
    "from sys import argv\n",
    "from phonlab.utils import dir2df\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get textgrid information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgdir = ('/home/ubuntu/Desktop/Shared/sf_Box_Sync/Diss_data/Fall_2019_LRAP/Word_lists/2018_vowels/2018_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnpat = '^(?P<spkr>[^_]+)_(?P<age_yrs>\\d+|adult)_(?P<task>.+)_(?P<word_list>\\d)\\.TextGrid$' # filenames\n",
    "\n",
    "\n",
    "tgdf = dir2df(\n",
    "    tgdir,\n",
    "    fnpat=fnpat,\n",
    "    addcols=['dirname', 'barename', 'ext']   # addcols spits out relevant file names\n",
    ")\n",
    "tgdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = []\n",
    "for row in tgdf.itertuples():\n",
    "    print(row.dirname+row.fname)\n",
    "    [phdf, wddf] = read_label(\n",
    "        os.path.join(row.dirname,row.fname), \n",
    "        'praat', tiers = ['Phone','Word'], \n",
    "        addcols=['dirname', 'barename', 'ext']\n",
    "    )\n",
    "    phdf['next_ph'] = phdf['Phone'].shift(-1)\n",
    "    phdf['prev_ph'] = phdf['Phone'].shift(1)\n",
    "                             \n",
    "    dflist.append(pd.merge_asof(phdf, wddf, on='t1', suffixes=['_ph', '_wd']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phwddf = pd.concat(dflist) # one df for all speakers with words and phones\n",
    "phwddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option to drop word list number from barename (for 2019 participants)\n",
    "tgdf['barename'] = tgdf['barename'].str.rsplit('_', 1).str[0]\n",
    "\n",
    "phwddf['barename_ph'] = phwddf['barename_ph'].str.rsplit('_', 1).str[0]\n",
    "phwddf['barename_wd'] = phwddf['barename_wd'].str.rsplit('_', 1).str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffinal = phwddf.merge(\n",
    "    tgdf,\n",
    "    left_on=['barename_ph'], \n",
    "    right_on=['barename'],\n",
    "    how='outer'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to create df with just relevant vowels\n",
    "voweldf = dffinal[\n",
    "    dffinal.Phone.isin(['a', 'e', 'i', 'o', 'u']) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove tokens under 50ms\n",
    "voweldf2 = voweldf[voweldf.t2_ph - voweldf.t1 >= .05] \n",
    "voweldf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function matches tg rows with nearest timestamp in covrdrdf, acdf, or ifcdf,  \n",
    "# and is required for the following functions\n",
    "\n",
    "def get_row_nearest_time(df, t, timecol): # timecol = timestamp col in df\n",
    "    '''Get the row nearest in time to specified value.\n",
    "    In case of tie, first row is returned.\n",
    "    ***NOTE***\n",
    "    df[timecol] must be sorted!!!\n",
    "    '''\n",
    "    return pd.DataFrame.from_records([df.loc[(df[timecol] - t).abs().idxmin()]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process \"formant\" .cov results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to match .cov meas and tg info\n",
    "\n",
    "def formant_cov_summary(row):\n",
    "    phone_dur = row.t2_ph - row.t1\n",
    "    midpt = (phone_dur*.5)+row.t1 \n",
    "    qrtr = (phone_dur*.25)+row.t1 \n",
    "    thrqrtr = (phone_dur*.75)+row.t1 \n",
    "\n",
    "    covdir = ('/home/ubuntu/Desktop/Shared/sf_Box_Sync/Diss_data/Fall_2019_LRAP/Word_lists/2018_vowels/2018_data/formants_cov')\n",
    "\n",
    "\n",
    "    covdr = EspsFormantReader(os.path.join(covdir, row.barename + '.fb')) # make an ESPS object of the associated .fb file\n",
    "    covdrdf = covdr.get_df(t1=row.t1, t2=row.t2_ph) # \n",
    "\n",
    "    midptrow = get_row_nearest_time(covdrdf, midpt, 'times')\n",
    "    midptdf = midptrow.rename(columns={\"times\": \"midpt_sec\", \"fm1\": \"midpt_f1\", \"fm2\": \"midpt_f2\", \"fm3\": \"midpt_f3\", \"fm4\": \"midpt_f4\"})\n",
    "    qrtrrow = get_row_nearest_time(covdrdf, qrtr, 'times')\n",
    "    qrtrdf = qrtrrow.rename(columns={\"times\": \"qrtr_sec\", \"fm1\": \"qrtr_f1\", \"fm2\": \"qrtr_f2\", \"fm3\": \"qrtr_f3\", \"fm4\": \"qrtr_f4\"})\n",
    "    thrqrtrrow = get_row_nearest_time(covdrdf, thrqrtr, 'times')\n",
    "    thrqrtrdf = thrqrtrrow.rename(columns={\"times\": \"thrqrtr_sec\", \"fm1\": \"thrqrtr_f1\", \"fm2\": \"thrqrtr_f2\", \"fm3\": \"thrqrtr_f3\", \"fm4\": \"thrqrtr_f4\"})\n",
    "\n",
    "    rowdf = pd.DataFrame([row])\n",
    "\n",
    "    rowdffinal = rowdf.reindex(columns=['t1', 't2_ph', 'prev_ph', 'next_ph', 'Phone', 'barename', 'Word', 'spkr', 'age_yrs', 'task']) # :=all rows, and these columns\n",
    "\n",
    "    return pd.concat(\n",
    "        [\n",
    "            midptdf.reindex(columns=['midpt_sec', 'midpt_f1', 'midpt_f2', 'midpt_f3', 'midpt_f4']), # subset relevant cols\n",
    "            qrtrdf.reindex(columns=['qrtr_sec', 'qrtr_f1', 'qrtr_f2', 'qrtr_f3', 'qrtr_f4']),\n",
    "            thrqrtrdf.reindex(columns=['thrqrtr_sec', 'thrqrtr_f1', 'thrqrtr_f2', 'thrqrtr_f3', 'thrqrtr_f4']),\n",
    "            rowdffinal # plus cols w/ metadata\n",
    "        ], \n",
    "        axis='columns' # add cols, not rows\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run the function to match formant meas and tg info\n",
    "\n",
    "covdflist = []\n",
    "\n",
    "for row in voweldf2.itertuples(): \n",
    "    covdflist.append(formant_cov_summary(row)) \n",
    "\n",
    "cov_final = pd.concat(covdflist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process \"formant\" .ac results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to match .ac meas and tg info\n",
    "\n",
    "def formant_ac_summary(row):\n",
    "    phone_dur = row.t2_ph - row.t1\n",
    "    midpt = (phone_dur*.5)+row.t1 \n",
    "    qrtr = (phone_dur*.25)+row.t1 \n",
    "    thrqrtr = (phone_dur*.75)+row.t1 \n",
    "\n",
    "    acdir = ('/home/ubuntu/Desktop/Shared/sf_Box_Sync/Diss_data/Fall_2019_LRAP/Word_lists/2018_vowels/2018_data/formants_ac')\n",
    "\n",
    "    acrdr = EspsFormantReader(os.path.join(acdir, row.barename + '.fb')) # make an ESPS object of the associated .fb file\n",
    "    acrdrdf = acrdr.get_df(t1=row.t1, t2=row.t2_ph) # \n",
    "\n",
    "    midptrow = get_row_nearest_time(acrdrdf, midpt, 'times')\n",
    "    midptdf = midptrow.rename(columns={\"times\": \"midpt_sec\", \"fm1\": \"midpt_f1\", \"fm2\": \"midpt_f2\", \"fm3\": \"midpt_f3\", \"fm4\": \"midpt_f4\"})\n",
    "    qrtrrow = get_row_nearest_time(acrdrdf, qrtr, 'times')\n",
    "    qrtrdf = qrtrrow.rename(columns={\"times\": \"qrtr_sec\", \"fm1\": \"qrtr_f1\", \"fm2\": \"qrtr_f2\", \"fm3\": \"qrtr_f3\", \"fm4\": \"qrtr_f4\"})\n",
    "    thrqrtrrow = get_row_nearest_time(acrdrdf, thrqrtr, 'times')\n",
    "    thrqrtrdf = thrqrtrrow.rename(columns={\"times\": \"thrqrtr_sec\", \"fm1\": \"thrqrtr_f1\", \"fm2\": \"thrqrtr_f2\", \"fm3\": \"thrqrtr_f3\", \"fm4\": \"thrqrtr_f4\"})\n",
    "\n",
    "    rowdf = pd.DataFrame([row])\n",
    "\n",
    "    rowdffinal = rowdf.reindex(columns=['t1', 't2_ph', 'prev_ph', 'next_ph', 'Phone', 'barename', 'Word', 'spkr', 'age_yrs', 'task']) # :=all rows, and these columns\n",
    "\n",
    "    return pd.concat(\n",
    "        [\n",
    "            midptdf.reindex(columns=['midpt_sec', 'midpt_f1', 'midpt_f2', 'midpt_f3', 'midpt_f4']), # subset relevant cols\n",
    "            qrtrdf.reindex(columns=['qrtr_sec', 'qrtr_f1', 'qrtr_f2', 'qrtr_f3', 'qrtr_f4']),\n",
    "            thrqrtrdf.reindex(columns=['thrqrtr_sec', 'thrqrtr_f1', 'thrqrtr_f2', 'thrqrtr_f3', 'thrqrtr_f4']),\n",
    "            rowdffinal # plus cols w/ metadata\n",
    "        ], \n",
    "        axis='columns' # add cols, not rows\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run the function to match formant meas and tg info\n",
    "\n",
    "acdflist = []\n",
    "\n",
    "for row in voweldf2.itertuples(): \n",
    "    acdflist.append(formant_ac_summary(row)) \n",
    "\n",
    "ac_final = pd.concat(acdflist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process ifc_formant results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to match meas and tg info\n",
    "\n",
    "def ifc_summary(row):\n",
    "    \n",
    "    phone_dur = row.t2_ph - row.t1\n",
    "    midpt = (phone_dur*.5)+row.t1 \n",
    "    qrtr = (phone_dur*.25)+row.t1 \n",
    "    thrqrtr = (phone_dur*.75)+row.t1 \n",
    "    \n",
    "    ifcdir = ('/home/ubuntu/Desktop/Shared/sf_Box_Sync/Diss_data/Fall_2019_LRAP/Word_lists/2018_vowels/2018_data/formants_ifc')\n",
    "\n",
    "    ifcname = row.barename + '.ifc' # get ifc filename (just a string)\n",
    "    df = pd.read_table(os.path.join(ifcdir, ifcname)) # big df of ifc values\n",
    "\n",
    "    midptrow = get_row_nearest_time(df, midpt, 'sec')\n",
    "    midptdf = midptrow.rename(columns={\"sec\": \"midpt_sec\", \"f1\": \"midpt_f1\", \"f2\": \"midpt_f2\", \"f3\": \"midpt_f3\", \"f4\": \"midpt_f4\"})\n",
    "    qrtrrow = get_row_nearest_time(df, qrtr, 'sec')\n",
    "    qrtrdf = qrtrrow.rename(columns={\"sec\": \"qrtr_sec\", \"f1\": \"qrtr_f1\", \"f2\": \"qrtr_f2\", \"f3\": \"qrtr_f3\", \"f4\": \"qrtr_f4\"})\n",
    "    thrqrtrrow = get_row_nearest_time(df, thrqrtr, 'sec')\n",
    "    thrqrtrdf = thrqrtrrow.rename(columns={\"sec\": \"thrqrtr_sec\", \"f1\": \"thrqrtr_f1\", \"f2\": \"thrqrtr_f2\", \"f3\": \"thrqrtr_f3\", \"f4\": \"thrqrtr_f4\"})\n",
    "\n",
    "    rowdf = pd.DataFrame([row])\n",
    "\n",
    "    rowdffinal = rowdf.reindex(columns=['t1', 't2_ph', 'prev_ph', 'next_ph', 'Phone', 'barename', 'Word', 'spkr', 'age_yrs', 'task']) # :=all rows, and these columns\n",
    "\n",
    "    return pd.concat([midptdf, qrtrdf, thrqrtrdf, rowdffinal], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function to match ifc meas and tg info\n",
    "ifclist = []\n",
    "\n",
    "\n",
    "for row in voweldf2.itertuples(): \n",
    "    ifclist.append(ifc_summary(row))\n",
    "  \n",
    "\n",
    "ifc_final = pd.concat(ifclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifc_final.head() # sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge results from three trackers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats = ['Phone', 't2_ph', 'Word', 'spkr', 'age_yrs', 'task']\n",
    "\n",
    "gettwo = pd.merge(    # merge ifc and ac dfs on filename and phone_t1\n",
    "    ifc_final, \n",
    "    ac_final.drop(repeats, axis='columns'),  \n",
    "    on=['barename', 't1'], \n",
    "    how='outer', \n",
    "    suffixes=['_ifc', '_ac']\n",
    ") \n",
    "\n",
    "allthree = pd.merge(    # merge ifc, ac, and cov dfs on filename and phone_t1\n",
    "    gettwo, \n",
    "    cov_final.drop(repeats, axis='columns'),  \n",
    "    on=['barename', 't1'], \n",
    "    how='outer'\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check - if every key had a match, should report FALSE\n",
    "# we ignore F4 calculations because when the lpc order = 10 (for kids) \n",
    "# esps cannot track f4 so nans are generated\n",
    "\n",
    "no_f4 = allthree.drop(['qrtr_f4', 'midpt_f4', 'thrqrtr_f4'], axis=1)\n",
    "\n",
    "np.any(no_f4.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate median formant meas for each point in vowel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median(row):\n",
    "    \n",
    "    # first clean up metadata\n",
    "    tokeep = ['spkr', 'age_yrs', 'Phone', 'Word', 'barename', 'task', 't1', 't2_ph', 'next_ph', 'prev_ph',\n",
    "             'qrtr_sec', 'midpt_sec', 'thrqrtr_sec', 'qrtr_sec_ifc', 'midpt_sec_ifc', 'thrqrtr_sec_ifc',\n",
    "             'qrtr_sec_ac', 'midpt_sec_ac', 'thrqrtr_sec_ac']\n",
    "    \n",
    "    \n",
    "    rowdf = pd.DataFrame([row]).reindex(columns=tokeep)\n",
    "    \n",
    "    \n",
    "    # now calculate median formant across trackers and formants\n",
    "    f1_qrtr = pd.DataFrame([\n",
    "        np.median(\n",
    "            np.array(\n",
    "                [row.qrtr_f1_ifc, row.qrtr_f1, row.qrtr_f1_ac]))], columns=['f1_qrtr_med'])\n",
    "    f1_midpt = pd.DataFrame([\n",
    "        np.median(\n",
    "            np.array(\n",
    "                [row.midpt_f1_ifc, row.midpt_f1, row.midpt_f1_ac]))], columns=['f1_midpt_med'])\n",
    "    f1_thrqrtr = pd.DataFrame([\n",
    "        np.median(\n",
    "            np.array(\n",
    "                [row.thrqrtr_f1_ifc, row.thrqrtr_f1, row.thrqrtr_f1_ac]))], columns=['f1_thrqrtr_med'])\n",
    "    \n",
    "    f2_qrtr = pd.DataFrame([\n",
    "        np.median(\n",
    "            np.array(\n",
    "                [row.qrtr_f2_ifc, row.qrtr_f2, row.qrtr_f2_ac]))], columns=['f2_qrtr_med'])\n",
    "    f2_midpt = pd.DataFrame([\n",
    "        np.median(\n",
    "            np.array(\n",
    "                [row.midpt_f2_ifc, row.midpt_f2, row.midpt_f2_ac]))], columns=['f2_midpt_med'])\n",
    "    f2_thrqrtr = pd.DataFrame(\n",
    "        [np.median(\n",
    "            np.array(\n",
    "                [row.thrqrtr_f2_ifc, row.thrqrtr_f2, row.thrqrtr_f2_ac]))], columns=['f2_thrqrtr_med'])\n",
    "    \n",
    "    f3_qrtr = pd.DataFrame(\n",
    "        [np.median(\n",
    "            np.array(\n",
    "                [row.qrtr_f3_ifc, row.qrtr_f3, row.qrtr_f3_ac]))], columns=['f3_qrtr_med'])\n",
    "    f3_midpt = pd.DataFrame(\n",
    "        [np.median(\n",
    "            np.array(\n",
    "                [row.midpt_f3_ifc, row.midpt_f3, row.midpt_f3_ac]))], columns=['f3_midpt_med'])\n",
    "    f3_thrqrtr = pd.DataFrame(\n",
    "        [np.median(\n",
    "            np.array(\n",
    "                [row.thrqrtr_f3_ifc, row.thrqrtr_f3, row.thrqrtr_f3_ac]))], columns=['f3_thrqrtr_med'])\n",
    "    \n",
    "    if row.age_yrs == 'adult': # only adults have f4 tracked\n",
    "        f4_qrtr = pd.DataFrame(\n",
    "            [np.median(\n",
    "                np.array(\n",
    "                    [row.qrtr_f4_ifc, row.qrtr_f4, row.qrtr_f4_ac]))], columns=['f4_qrtr_med'])\n",
    "        f4_midpt = pd.DataFrame(\n",
    "            [np.median(\n",
    "                np.array(\n",
    "                    [row.midpt_f4_ifc, row.midpt_f4, row.midpt_f4_ac]))], columns=['f4_midpt_med'])\n",
    "        f4_thrqrtr = pd.DataFrame(\n",
    "            [np.median(\n",
    "                np.array(\n",
    "                    [row.thrqrtr_f4_ifc, row.thrqrtr_f4, row.thrqrtr_f4_ac]))], columns=['f4_thrqrtr_med'])\n",
    "        \n",
    "        return pd.concat([f1_qrtr,  f1_midpt, f1_thrqrtr,\n",
    "                          f2_qrtr, f2_midpt, f2_thrqrtr,\n",
    "                          f3_qrtr, f3_midpt, f3_thrqrtr,\n",
    "                          f4_qrtr, f4_midpt, f4_thrqrtr,\n",
    "                          rowdf], axis=1)\n",
    "    else: # be prepared for the absence of f4 in the final df to potentially throw an error once kid data included \n",
    "               \n",
    "        return pd.concat([f1_qrtr,  f1_midpt, f1_thrqrtr,\n",
    "                          f2_qrtr, f2_midpt, f2_thrqrtr,\n",
    "                          f3_qrtr, f3_midpt, f3_thrqrtr,\n",
    "                          rowdf], axis=1) # rowdf contains speaker metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now calculate median meas for each formant at 25, 50, and 75% of each vowel\n",
    "\n",
    "medlist = []\n",
    "\n",
    "for row in allthree.itertuples(): # loop through all rows in the df with ifc, cov, and ac measurements\n",
    "    get_median(row)\n",
    "    medlist.append(get_median(row))\n",
    "  \n",
    "\n",
    "medfinal = pd.concat(medlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medfinal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data\n",
    "medfinal.to_csv('med_formants.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
